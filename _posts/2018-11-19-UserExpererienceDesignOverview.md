---
layout: post
title: Amarteur Hour
subtitle: A User Experience Design Overview
---

# Team Member Names and Roles

Noah Nsangou: Visual designer, ideator
Anjali Pai: Visual Designer, Ideator
Williams Downs: Ideator, Note-Taker, Head Writer

# Problem and Solution Overview

Art museums can often inspire feelings of self-consciousness for those who feel like their opinions are not valid or who feel intimidated by the quiet, serious atmosphere that art museums often exude. As a solution, we propose a QR-code enabled web-app that allows museum-goers to share their emotional reaction to an artwork through a simple panel of faces expressing different moods. The user then receives information about the number of attendees who felt either the same emotion (if there are enough people) or the number of attendees who fell in the same category of emotions. This category of similarity is widened as necessary to ensure that each person is guaranteed a validating response. An additional wall-mounted interactive display component takes all of the user-provided data and creates a mass visualization of emotions for each artwork, represented through animations of groups of people. By interacting with the display, museum-goers can view and interact with comments that other people have left, thus building a sense of community founded on ranges of different reactions.


# Initial Paper Prototype 

After a series of exercises investigating what amateur users desired from art museums and what tasks would help them reach those desires (see [Art for Amarteurs](https://williamdowns.github.io/amarteurs/2018-10-25-UserExperienceResearchOverview/)), we developed a paper prototype of a design (as described in the overview above). Our original paper prototype contained two components: a web-based app, which we delivered using a cardboard mobile phone, and a interactive visual display, which we simulated using a large posterboard. The web-based app had a series of screens letting users emotionally react to a piece of art, see how many people responded to that piece of art, comment on a piece of art, and see “similar” comments from other people about that piece of art. On the large interactive visual display, users could select a piece of art, select an emotional response to that piece of art and see how many people responded with that emotion. Users could also see all comments from people who reacted with this emotion, and respond in text or stylus writing to any comment. Below is an overview of our initial prototype, showing both the phone and large interactive display components.
![Imgur](https://i.imgur.com/iOxzIfR.jpg)


Both of these prototypes facilitated our two primary tasks. Our two primary tasks were:
* Find a piece of art and share an emotional response. Figure out how many people felt the same way as you. Here are the emotional response selection and post-submission screens:

![Imgur](https://i.imgur.com/4Lrf5Hr.jpg)
![Imgur](https://i.imgur.com/jW4zg7M.jpg)

* Leave a comment about an artwork and see how people who felt differently reacted. Here is the large display's comment feed screen:
![Imgur](https://i.imgur.com/TYC7cNW.jpg)

Through these tasks users can leave their own responses, feel community by seeing responses from people who think similarly, and explore how people with other opinions feel. For more details, visit [Paper Prototype](https://williamdowns.github.io/amarteurs/2018-10-29-PaperPrototype/).

# Testing Process

To test the clarity and usability of our design, we conducted three forms of investigation. The first was a heuristic evaluation where we had two groups of users (handpicked from our classmates) walk through our two primary tasks on our paper prototype. The goal was to identify heuristics of good design on which our paper prototype failed. We then updated our design to ensure that we were heuristically sound. For more details, visit [Heuristic Evaluations](https://williamdowns.github.io/amarteurs/2018-11-01-HeuristicEvaluations/). The next step of our testing was to consider the cognitive process of using our app. We ran a cognitive walkthrough to determine if the steps required to complete our core tasks with our app followed logically from each other. 



Our final and most intensive testing step was to test our design in a more realistic setting, with people in our target user-group. In order to accomplish this, we ran three usability tests. All of the tests were held in a study room in Schow library, which we outfitted to simulate a gallery in a museum featuring our design. By doing so, we provided a scenario in which our design would be used, and placed the user in realistic conditions while still having an uninterrupted, quiet environment. Two of our participants fit into the category of “art amateurs” (self-defined) and one fell somewhere between an “art amateur” and an “art enthusiast”. After our first usability test, we discovered that our protocol needed to be slightly modified to provide users with a slightly higher baseline of context about the design. We made that modification, which greatly improved our next two usability tests.


In retrospect, our testing process definitely shifted as we ran more tests on our paper prototype. In our first few tests we were unsure about exactly how the user would interact with the web-app and the interactive display. After observing a few interactions, however, we began to understand the relationship between the two components better and we were able to use that to change our tasks such that we were explicitly forcing the user to think about the connection between the app and the display. This helped us figure out where there were gaps in understanding.


# Testing Results


# Final Paper Prototype


# Digital Mockup


# Discussion


# Appendix
